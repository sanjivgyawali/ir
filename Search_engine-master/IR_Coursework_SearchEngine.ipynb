{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-ratio",
   "metadata": {},
   "source": [
    "# Information Retrieval Coursework (7071CEM)\n",
    "\n",
    "Task:\n",
    "Develop a vertical search engine similar to Google Scholar that only retrieves papers/books published by a member of Coventry University. As such, at least one of the co-authors must be a Coventry University Staff member. \n",
    "\n",
    "To this end, the profiles of academic staff at CU available on the CU web site are crawled, and their papers within their profiles are indexed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amateur-simple",
   "metadata": {},
   "source": [
    "## Package Installs\n",
    "\n",
    "Some packages required for this task are by default not included in the jupyter notebooks package list. A pip-install of these packages is required. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static-registration",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "external-guatemala",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T00:58:01.977307Z",
     "start_time": "2021-08-01T00:58:01.962437Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scrapy in c:\\users\\chetn\\anaconda3\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: cryptography>=3.4.6 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from scrapy) (39.0.1)\n",
      "Requirement already satisfied: parsel>=1.5.0 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from scrapy) (1.6.0)\n",
      "Requirement already satisfied: itemloaders>=1.0.1 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from scrapy) (1.0.4)\n",
      "Requirement already satisfied: itemadapter>=0.1.0 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from scrapy) (0.3.0)\n",
      "Requirement already satisfied: w3lib>=1.17.0 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from scrapy) (1.21.0)\n",
      "Requirement already satisfied: zope.interface>=5.1.0 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from scrapy) (5.4.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from scrapy) (65.6.3)\n",
      "Requirement already satisfied: tldextract in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from scrapy) (3.2.0)\n",
      "Requirement already satisfied: Twisted>=18.9.0 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from scrapy) (22.2.0)\n",
      "Requirement already satisfied: queuelib>=1.4.2 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from scrapy) (1.5.0)\n",
      "Requirement already satisfied: PyDispatcher>=2.0.5 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from scrapy) (2.0.5)\n",
      "Requirement already satisfied: packaging in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from scrapy) (22.0)\n",
      "Requirement already satisfied: cssselect>=0.9.1 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from scrapy) (1.1.0)\n",
      "Requirement already satisfied: service-identity>=18.1.0 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from scrapy) (18.1.0)\n",
      "Requirement already satisfied: pyOpenSSL>=21.0.0 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from scrapy) (23.0.0)\n",
      "Requirement already satisfied: protego>=0.1.15 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from scrapy) (0.1.16)\n",
      "Requirement already satisfied: lxml>=4.3.0 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from scrapy) (4.9.1)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from cryptography>=3.4.6->scrapy) (1.15.1)\n",
      "Requirement already satisfied: jmespath>=0.9.5 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from itemloaders>=1.0.1->scrapy) (0.10.0)\n",
      "Requirement already satisfied: six>=1.6.0 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from parsel>=1.5.0->scrapy) (1.16.0)\n",
      "Requirement already satisfied: attrs>=16.0.0 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from service-identity>=18.1.0->scrapy) (22.1.0)\n",
      "Requirement already satisfied: pyasn1 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from service-identity>=18.1.0->scrapy) (0.4.8)\n",
      "Requirement already satisfied: pyasn1-modules in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from service-identity>=18.1.0->scrapy) (0.2.8)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from Twisted>=18.9.0->scrapy) (4.4.0)\n",
      "Requirement already satisfied: constantly>=15.1 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from Twisted>=18.9.0->scrapy) (15.1.0)\n",
      "Requirement already satisfied: incremental>=21.3.0 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from Twisted>=18.9.0->scrapy) (21.3.0)\n",
      "Requirement already satisfied: twisted-iocpsupport<2,>=1.0.2 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from Twisted>=18.9.0->scrapy) (1.0.2)\n",
      "Requirement already satisfied: Automat>=0.8.0 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from Twisted>=18.9.0->scrapy) (20.2.0)\n",
      "Requirement already satisfied: hyperlink>=17.1.1 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from Twisted>=18.9.0->scrapy) (21.0.0)\n",
      "Requirement already satisfied: idna in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from tldextract->scrapy) (3.4)\n",
      "Requirement already satisfied: requests-file>=1.4 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from tldextract->scrapy) (1.5.1)\n",
      "Requirement already satisfied: filelock>=3.0.8 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from tldextract->scrapy) (3.9.0)\n",
      "Requirement already satisfied: requests>=2.1.0 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from tldextract->scrapy) (2.28.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=3.4.6->scrapy) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy) (1.26.14)\n",
      "Requirement already satisfied: requests in c:\\users\\chetn\\anaconda3\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from requests) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from requests) (2022.12.7)\n",
      "Requirement already satisfied: BeautifulSoup4 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from BeautifulSoup4) (2.3.2.post1)\n",
      "Requirement already satisfied: nltk in c:\\users\\chetn\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: click in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from nltk) (1.1.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: gensim in c:\\users\\chetn\\anaconda3\\lib\\site-packages (4.3.0)\n",
      "Requirement already satisfied: FuzzyTM>=0.4.0 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from gensim) (2.0.5)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from gensim) (1.23.5)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from gensim) (1.10.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from FuzzyTM>=0.4.0->gensim) (1.5.3)\n",
      "Requirement already satisfied: pyfume in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from FuzzyTM>=0.4.0->gensim) (0.2.25)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2022.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2.8.2)\n",
      "Requirement already satisfied: simpful in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (2.11.0)\n",
      "Requirement already satisfied: fst-pso in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (1.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->FuzzyTM>=0.4.0->gensim) (1.16.0)\n",
      "Requirement already satisfied: miniful in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from fst-pso->pyfume->FuzzyTM>=0.4.0->gensim) (0.0.6)\n",
      "Requirement already satisfied: xgboost in c:\\users\\chetn\\anaconda3\\lib\\site-packages (1.7.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from xgboost) (1.23.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from xgboost) (1.10.0)\n",
      "Requirement already satisfied: pandastable in c:\\users\\chetn\\anaconda3\\lib\\site-packages (0.13.1)\n",
      "Requirement already satisfied: pandas>=1.5 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from pandastable) (1.5.3)\n",
      "Requirement already satisfied: matplotlib>=3.0 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from pandastable) (3.7.0)\n",
      "Requirement already satisfied: future in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from pandastable) (0.18.3)\n",
      "Requirement already satisfied: numexpr>=2.4 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from pandastable) (2.8.4)\n",
      "Requirement already satisfied: xlrd>=0.9 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from pandastable) (2.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from matplotlib>=3.0->pandastable) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from matplotlib>=3.0->pandastable) (1.23.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from matplotlib>=3.0->pandastable) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from matplotlib>=3.0->pandastable) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from matplotlib>=3.0->pandastable) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from matplotlib>=3.0->pandastable) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from matplotlib>=3.0->pandastable) (22.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from matplotlib>=3.0->pandastable) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from matplotlib>=3.0->pandastable) (1.4.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from pandas>=1.5->pandastable) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\chetn\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0->pandastable) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Delete the \"#\" before each subsequent line to install the package\n",
    "\n",
    "!pip install scrapy\n",
    "!pip install requests\n",
    "!pip install BeautifulSoup4\n",
    "!pip install nltk\n",
    "!pip install gensim\n",
    "!pip install xgboost\n",
    "!pip install pandastable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "latin-pioneer",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T00:58:06.417024Z",
     "start_time": "2021-08-01T00:58:01.980987Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\chetn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\chetn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\chetn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\chetn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import string\n",
    "import json\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-capitol",
   "metadata": {},
   "source": [
    "# 1. Crawler Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "million-marks",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T00:58:06.423826Z",
     "start_time": "2021-08-01T00:58:06.420176Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define Seed Page\n",
    "URL = \"https://pureportal.coventry.ac.uk/en/organisations/coventry-university/persons/\"\n",
    "\n",
    "# Define profile URL format. This was obtained by manually examining the profile pages\n",
    "profile_url = \"https://pureportal.coventry.ac.uk/en/persons/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cathedral-repeat",
   "metadata": {},
   "source": [
    "The seed page, i.e coventry researchers profiles landing page, contains profiles of all academic researchers of the University. As there are up to 2206 results, a limited number are displayed at once (50).\n",
    "\n",
    "Even if new profiles are added and a new page is required, the crawler will need to crawl through all pages to access every profile. To do this, a function is defined to retrieve the current total number of result pages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "formal-shift",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T00:58:09.277766Z",
     "start_time": "2021-08-01T00:58:06.428114Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_maximum_page():\n",
    "    \n",
    "    first = requests.get(URL)\n",
    "    soup = BeautifulSoup(first.text, 'html.parser')\n",
    "    final_page = soup.select('#main-content > div > section > nav > ul > li:nth-child(12) > a')[0]['href']\n",
    "    fp = final_page.split('=')[-1]\n",
    "    return int(fp)\n",
    "    \n",
    "mx = get_maximum_page()\n",
    "mx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-mustang",
   "metadata": {},
   "source": [
    "Instead of crawling all researchers, this web crawler is designed to specifically find researchers who:\n",
    "    \n",
    "1. Have research publications\n",
    "2. Are part of the \"**School of Computing, Electronics and Maths**\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "hidden-sugar",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T00:58:09.407285Z",
     "start_time": "2021-08-01T00:58:09.280073Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_department(researcher):\n",
    "    \n",
    "    l1 = researcher.find('div', class_='rendering_person_short')\n",
    "      \n",
    "    for span in l1.find_all('span'):\n",
    "        # Check department\n",
    "        print(span.text)\n",
    "        if span.text == str('Centre for Intelligent Healthcare'):\n",
    "            name = researcher.find('h3', class_='title').find('span').text\n",
    "            return name\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "def create_csv():\n",
    "     database = pd.DataFrame(columns=['Title', 'Author', 'Published', 'Link'])\n",
    "     database.to_csv('database.csv')\n",
    "    \n",
    "def update_csv(database):\n",
    "    current_data = pd.read_csv(database, index_col=\"Unnamed: 0\")\n",
    "    return current_data        \n",
    "\n",
    "def enter_each_researchers_publication(researcher, url, df):\n",
    "    \n",
    "    new_url = url + str(researcher).replace(' ','-').lower() + '/publications/'\n",
    "    page = requests.get(new_url)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    results = soup.find(id=\"main-content\")\n",
    "    papers = results.find_all(\"li\", class_=\"list-result-item\")\n",
    "    \n",
    "    \n",
    "    for paper in papers:\n",
    "        title = paper.find('h3', class_='title').find('span')\n",
    "        author = paper.find('a', class_='link person').find('span')\n",
    "        date = paper.find('span', class_=\"date\")\n",
    "        link = paper.find('h3', class_='title').find('a', href=True)['href']\n",
    "        \n",
    "        opening = pd.read_csv('database.csv', index_col=\"Unnamed: 0\")\n",
    "        opening = opening.append({'Title': title.text, \n",
    "                                  'Author': author.text, \n",
    "                                  'Published': date.text,\n",
    "                                  'Link': link}, ignore_index=True)\n",
    "        opening.to_csv('database.csv')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "accessory-customer",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T00:58:09.442618Z",
     "start_time": "2021-08-01T00:58:09.431490Z"
    }
   },
   "outputs": [],
   "source": [
    "## Scrape function\n",
    "def scrape(mx):\n",
    "    df = update_csv('database.csv')\n",
    "    i=0\n",
    "    while True:\n",
    "    \n",
    "        if i > 17:\n",
    "            break\n",
    "            \n",
    "        if i>0:\n",
    "            url = URL + '?page=' + str(i)\n",
    "        else:\n",
    "            url = URL\n",
    "    \n",
    "        i = i+1\n",
    "        # scraping starts here\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "        results = soup.find(id=\"main-content\")\n",
    "        researchers = results.find_all(\"li\", class_=\"grid-result-item\")\n",
    "\n",
    "        for researcher in researchers:\n",
    "            # Check if researcher has any papers\n",
    "            check = researcher.find('div', class_='stacked-trend-widget')\n",
    "            if check:\n",
    "                name = check_department(researcher)\n",
    "                if name is None:\n",
    "                    pass\n",
    "                else:\n",
    "                    enter_each_researchers_publication(name, profile_url, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "absent-vegetable",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T00:59:40.554457Z",
     "start_time": "2021-08-01T00:58:09.447859Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aliano Abbasi\n",
      "Research Centre for Business in Society\n",
      "Person: \n",
      "Sally Abbott\n",
      "Centre for Healthcare and Communities\n",
      " - \n",
      "Assistant Professor (Research)\n",
      "Person: \n",
      "Mohamed Abdelshafy\n",
      "School of Computing, Mathematics and Data Sciences\n",
      " - \n",
      "Assistant Professor Academic\n",
      "Person: \n",
      "Mohamad Nazri Abd Karim\n",
      "School of Economics, Finance and Accounting\n",
      " - \n",
      "Lecturer in Finance\n",
      "Person: \n",
      "Al-Noor Abdullah\n",
      "School of Strategy and Leadership\n",
      " - \n",
      "Lecturer in Business Management\n",
      "Person: \n",
      "Muhammad Abdullah\n",
      "School of Economics, Finance and Accounting\n",
      " - \n",
      "Lecturer in Finance\n",
      "Person: \n",
      "Rakib Abdur\n",
      "Centre for Future Transport and Cities\n",
      " - \n",
      "Associate Professor (Systems Security)\n",
      "Person: \n",
      "Jackie Abell\n",
      "Centre for Agroecology, Water and Resilience\n",
      " - \n",
      "Associate Professor Research\n",
      "Person: \n",
      "Adam Abukari\n",
      "Research Centre for Financial & Corporate Integrity\n",
      " - \n",
      "Assistant Professor (Research)\n",
      "Person: \n",
      "Abiodun 'Abbey' Adanikin\n",
      "Centre for Healthcare and Communities\n",
      " - \n",
      "Assistant Professor (Research)\n",
      "Person: \n",
      "Victor Aderogba Adebiyi\n",
      "Centre for Agroecology, Water and Resilience\n",
      "Person: \n",
      "Tunde Adediran\n",
      "School of Strategy and Leadership\n",
      " - \n",
      "Lecturer in Project Management\n",
      "Person: \n",
      "Oluwadunsin Adekola\n",
      "Centre for Agroecology, Water and Resilience\n",
      " - \n",
      "Postdoctoral Research Fellow\n",
      "Person: \n",
      "Janneke Adema\n",
      "Research Centre in Postdigital Cultures\n",
      " - \n",
      "Associate Professor (Research)\n",
      "Person: \n",
      "James Adie\n",
      "School of Psychological, Social and Behavioural Sciences\n",
      " - \n",
      "Assistant Professor Academic\n",
      "Person: \n",
      "Louise Adkins\n",
      "School of Art and Design\n",
      " - \n",
      "Assistant Professor Academic\n",
      "Person: \n",
      "Araz Agha\n",
      "School of Energy, Construction and Environment\n",
      " - \n",
      "Assistant Professor (Academic)\n",
      "Person: \n",
      "Daniel Aghanya\n",
      "School of Economics, Finance and Accounting\n",
      " - \n",
      "Assistant Professor (Academic)\n",
      "Person: \n",
      "Bilal Ahmad\n",
      "Centre for Manufacturing and Materials\n",
      " - \n",
      "Research Fellow\n",
      "Person: \n",
      "Zahir Ahmad\n",
      "School of Future Transport Engineering\n",
      " - \n",
      "Curriculum Lead (Associate Professor - Academic)\n",
      "Person: \n",
      "Hany Ahmed\n",
      "School of Economics, Finance and Accounting\n",
      " - \n",
      "Lecturer in Finance\n",
      "Person: \n",
      "Mohammed Ahmed\n",
      "School of Strategy and Leadership\n",
      " - \n",
      "Lecturer in Project Management\n",
      "Person: \n",
      "Sarfraz Ahmed\n",
      "Centre for Manufacturing and Materials\n",
      "Person: \n",
      "Nurudeen Aigoro\n",
      "Centre for Future Transport and Cities\n",
      "Person: \n",
      "Olubunmi Ajala\n",
      "School of Economics, Finance and Accounting\n",
      " - \n",
      "Lecturer\n",
      "Person: \n",
      "Michael Ajao-Olarinoye\n",
      "Research Centre for Computational Science and Mathematical Modelling\n",
      "Person: \n",
      "Damilola Akinniyi\n",
      "School of Energy, Construction and Environment\n",
      " - \n",
      "Assistant Lecturer in Civil Engineering\n",
      "Person: \n",
      "Ebenezer Akore Yeboah\n",
      "Person\n",
      "Michail Akritidis\n",
      "Research Centre for Fluid and Complex Systems\n",
      "Person: \n",
      "Lara Alamad\n",
      "School of Nursing, Midwifery and Health\n",
      " - \n",
      "Assistant Professor (Academic)\n",
      "Person: \n",
      "Samir Alamad\n",
      "School of Economics, Finance and Accounting\n",
      " - \n",
      "Assistant Professor (Academic)\n",
      "Person: \n",
      "Mahsa Alami Fariman\n",
      "School of Energy, Construction and Environment\n",
      " - \n",
      "Assistant Lecturer in Planning & Urban Environments\n",
      "Person: \n",
      "Saif Faris Ahmad Alatrash\n",
      "Research Centre in Postdigital Cultures\n",
      "Person: \n",
      "Ammar Al Bazi\n",
      "Faculty of Engineering, Environment & Computing\n",
      " - \n",
      "EEC Visitor\n",
      "Person: \n",
      "Reda Al-Bodour\n",
      "School of Computing, Mathematics and Data Sciences\n",
      " - \n",
      "Deputy Head of School\n",
      "Person: \n",
      "Tim Aldsworth\n",
      "School of Life Sciences\n",
      " - \n",
      "Assistant Professor Academic\n",
      "Person: \n",
      "Alaa Alhaj Ismail\n",
      "Research Centre for Financial & Corporate Integrity\n",
      " - \n",
      "Assistant Professor (Research)\n",
      "Person: \n",
      "Emran Ali\n",
      "Research Centre for Computational Science and Mathematical Modelling\n",
      "Person: \n",
      "Rashid Ali\n",
      "School of Future Transport Engineering\n",
      " - \n",
      "Assistant Professor Academic\n",
      "Person: \n",
      "Reza Ali\n",
      "School of Future Transport Engineering\n",
      " - \n",
      "Deputy Head of School\n",
      "Person: \n",
      "Mabel Alkali\n",
      "Centre for Trust, Peace and Social Relations\n",
      "Person: \n",
      "Khaled Al Khudir\n",
      "School of Mechanical Engineering\n",
      " - \n",
      "Lecturer in Control Engineering\n",
      "Person: \n",
      "John Allen\n",
      "Centre for Intelligent Healthcare\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chetn\\AppData\\Local\\Temp\\ipykernel_10056\\2389500772.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  opening = opening.append({'Title': title.text,\n",
      "C:\\Users\\chetn\\AppData\\Local\\Temp\\ipykernel_10056\\2389500772.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  opening = opening.append({'Title': title.text,\n",
      "C:\\Users\\chetn\\AppData\\Local\\Temp\\ipykernel_10056\\2389500772.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  opening = opening.append({'Title': title.text,\n",
      "C:\\Users\\chetn\\AppData\\Local\\Temp\\ipykernel_10056\\2389500772.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  opening = opening.append({'Title': title.text,\n",
      "C:\\Users\\chetn\\AppData\\Local\\Temp\\ipykernel_10056\\2389500772.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  opening = opening.append({'Title': title.text,\n",
      "C:\\Users\\chetn\\AppData\\Local\\Temp\\ipykernel_10056\\2389500772.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  opening = opening.append({'Title': title.text,\n",
      "C:\\Users\\chetn\\AppData\\Local\\Temp\\ipykernel_10056\\2389500772.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  opening = opening.append({'Title': title.text,\n",
      "C:\\Users\\chetn\\AppData\\Local\\Temp\\ipykernel_10056\\2389500772.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  opening = opening.append({'Title': title.text,\n",
      "C:\\Users\\chetn\\AppData\\Local\\Temp\\ipykernel_10056\\2389500772.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  opening = opening.append({'Title': title.text,\n",
      "C:\\Users\\chetn\\AppData\\Local\\Temp\\ipykernel_10056\\2389500772.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  opening = opening.append({'Title': title.text,\n",
      "C:\\Users\\chetn\\AppData\\Local\\Temp\\ipykernel_10056\\2389500772.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  opening = opening.append({'Title': title.text,\n",
      "C:\\Users\\chetn\\AppData\\Local\\Temp\\ipykernel_10056\\2389500772.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  opening = opening.append({'Title': title.text,\n",
      "C:\\Users\\chetn\\AppData\\Local\\Temp\\ipykernel_10056\\2389500772.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  opening = opening.append({'Title': title.text,\n",
      "C:\\Users\\chetn\\AppData\\Local\\Temp\\ipykernel_10056\\2389500772.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  opening = opening.append({'Title': title.text,\n",
      "C:\\Users\\chetn\\AppData\\Local\\Temp\\ipykernel_10056\\2389500772.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  opening = opening.append({'Title': title.text,\n",
      "C:\\Users\\chetn\\AppData\\Local\\Temp\\ipykernel_10056\\2389500772.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  opening = opening.append({'Title': title.text,\n",
      "C:\\Users\\chetn\\AppData\\Local\\Temp\\ipykernel_10056\\2389500772.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  opening = opening.append({'Title': title.text,\n",
      "C:\\Users\\chetn\\AppData\\Local\\Temp\\ipykernel_10056\\2389500772.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  opening = opening.append({'Title': title.text,\n",
      "C:\\Users\\chetn\\AppData\\Local\\Temp\\ipykernel_10056\\2389500772.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  opening = opening.append({'Title': title.text,\n",
      "C:\\Users\\chetn\\AppData\\Local\\Temp\\ipykernel_10056\\2389500772.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  opening = opening.append({'Title': title.text,\n",
      "C:\\Users\\chetn\\AppData\\Local\\Temp\\ipykernel_10056\\2389500772.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  opening = opening.append({'Title': title.text,\n",
      "C:\\Users\\chetn\\AppData\\Local\\Temp\\ipykernel_10056\\2389500772.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  opening = opening.append({'Title': title.text,\n",
      "C:\\Users\\chetn\\AppData\\Local\\Temp\\ipykernel_10056\\2389500772.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  opening = opening.append({'Title': title.text,\n",
      "C:\\Users\\chetn\\AppData\\Local\\Temp\\ipykernel_10056\\2389500772.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  opening = opening.append({'Title': title.text,\n",
      "C:\\Users\\chetn\\AppData\\Local\\Temp\\ipykernel_10056\\2389500772.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  opening = opening.append({'Title': title.text,\n",
      "C:\\Users\\chetn\\AppData\\Local\\Temp\\ipykernel_10056\\2389500772.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  opening = opening.append({'Title': title.text,\n",
      "C:\\Users\\chetn\\AppData\\Local\\Temp\\ipykernel_10056\\2389500772.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  opening = opening.append({'Title': title.text,\n",
      "C:\\Users\\chetn\\AppData\\Local\\Temp\\ipykernel_10056\\2389500772.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  opening = opening.append({'Title': title.text,\n",
      "C:\\Users\\chetn\\AppData\\Local\\Temp\\ipykernel_10056\\2389500772.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  opening = opening.append({'Title': title.text,\n",
      "C:\\Users\\chetn\\AppData\\Local\\Temp\\ipykernel_10056\\2389500772.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  opening = opening.append({'Title': title.text,\n",
      "C:\\Users\\chetn\\AppData\\Local\\Temp\\ipykernel_10056\\2389500772.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  opening = opening.append({'Title': title.text,\n",
      "C:\\Users\\chetn\\AppData\\Local\\Temp\\ipykernel_10056\\2389500772.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  opening = opening.append({'Title': title.text,\n",
      "C:\\Users\\chetn\\AppData\\Local\\Temp\\ipykernel_10056\\2389500772.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  opening = opening.append({'Title': title.text,\n",
      "C:\\Users\\chetn\\AppData\\Local\\Temp\\ipykernel_10056\\2389500772.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  opening = opening.append({'Title': title.text,\n",
      "C:\\Users\\chetn\\AppData\\Local\\Temp\\ipykernel_10056\\2389500772.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  opening = opening.append({'Title': title.text,\n",
      "C:\\Users\\chetn\\AppData\\Local\\Temp\\ipykernel_10056\\2389500772.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  opening = opening.append({'Title': title.text,\n",
      "C:\\Users\\chetn\\AppData\\Local\\Temp\\ipykernel_10056\\2389500772.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  opening = opening.append({'Title': title.text,\n",
      "C:\\Users\\chetn\\AppData\\Local\\Temp\\ipykernel_10056\\2389500772.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  opening = opening.append({'Title': title.text,\n",
      "C:\\Users\\chetn\\AppData\\Local\\Temp\\ipykernel_10056\\2389500772.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  opening = opening.append({'Title': title.text,\n",
      "C:\\Users\\chetn\\AppData\\Local\\Temp\\ipykernel_10056\\2389500772.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  opening = opening.append({'Title': title.text,\n",
      "C:\\Users\\chetn\\AppData\\Local\\Temp\\ipykernel_10056\\2389500772.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  opening = opening.append({'Title': title.text,\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m<timed eval>:1\u001b[0m\n",
      "Cell \u001b[1;32mIn[16], line 30\u001b[0m, in \u001b[0;36mscrape\u001b[1;34m(mx)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 30\u001b[0m     \u001b[43menter_each_researchers_publication\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 33\u001b[0m, in \u001b[0;36menter_each_researchers_publication\u001b[1;34m(researcher, url, df)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m paper \u001b[38;5;129;01min\u001b[39;00m papers:\n\u001b[0;32m     32\u001b[0m     title \u001b[38;5;241m=\u001b[39m paper\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh3\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspan\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m     author \u001b[38;5;241m=\u001b[39m \u001b[43mpaper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ma\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlink person\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspan\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     34\u001b[0m     date \u001b[38;5;241m=\u001b[39m paper\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspan\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     35\u001b[0m     link \u001b[38;5;241m=\u001b[39m paper\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh3\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, href\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find'"
     ]
    }
   ],
   "source": [
    "create_csv()\n",
    "update_csv(database='database.csv') #create_csv\n",
    "\n",
    "%time scrape(mx) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "associate-subscription",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T00:59:40.569218Z",
     "start_time": "2021-08-01T00:59:40.557023Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 records were scraped\n"
     ]
    }
   ],
   "source": [
    "sample_db = pd.read_csv('database.csv').rename(columns={'Unnamed: 0':'SN'})\n",
    "sample_db\n",
    "print(f'{sample_db.shape[0]} records were scraped')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "herbal-desktop",
   "metadata": {},
   "source": [
    "# 2. Indexing Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-potter",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T00:59:40.600384Z",
     "start_time": "2021-08-01T00:59:40.572032Z"
    }
   },
   "outputs": [],
   "source": [
    "scraped_db = pd.read_csv('database.csv').rename(columns={'Unnamed: 0':'SN'}).reset_index(drop=True)\n",
    "scraped_db.head()\n",
    "# scraped_db = pd.read_csv('database.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-coordinate",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T07:22:25.795248Z",
     "start_time": "2021-08-01T07:22:25.784819Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_db.head(7)\n",
    "#ids = scraped_db[\"Title\"]\n",
    "#scraped_db[ids.isin(ids[ids.duplicated()])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-trauma",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T00:59:40.612357Z",
     "start_time": "2021-08-01T00:59:40.603287Z"
    }
   },
   "outputs": [],
   "source": [
    "single_row = scraped_db.loc[1,:].copy()\n",
    "single_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-humor",
   "metadata": {},
   "source": [
    "## 2.1 Preprocess Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-train",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T00:59:40.647183Z",
     "start_time": "2021-08-01T00:59:40.615161Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove stop words\n",
    "sw = stopwords.words(\"english\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def tp1(txt):\n",
    "    txt = txt.lower()   # Make lowercase\n",
    "    txt = txt.translate(str.maketrans('',\n",
    "                                      '',\n",
    "                                      string.punctuation))   # Remove punctuation marks\n",
    "    txt = lematize(txt)\n",
    "    return txt\n",
    "\n",
    "\n",
    "def fwpt(word):\n",
    "    tag = pos_tag([word])[0][1][0].upper()\n",
    "    hash_tag = {\"V\": wordnet.VERB, \"R\": wordnet.ADV,\"N\": wordnet.NOUN,\"J\": wordnet.ADJ}         \n",
    "    return hash_tag.get(tag, wordnet.NOUN)\n",
    "\n",
    "def lematize(text):\n",
    "        tkns = nltk.word_tokenize(text)\n",
    "        ax = \"\"\n",
    "        for each in tkns:\n",
    "            if each not in sw:\n",
    "                ax += lemmatizer.lemmatize(each, fwpt(each)) + \" \"\n",
    "        return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fixed-triple",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T00:59:40.670745Z",
     "start_time": "2021-08-01T00:59:40.658588Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sample title\n",
    "single_row['Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-strain",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T00:59:43.014244Z",
     "start_time": "2021-08-01T00:59:40.699046Z"
    }
   },
   "outputs": [],
   "source": [
    "# Demonstration of lowercase and punctuation removal\n",
    "tp1(single_row['Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinated-columbus",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T00:59:43.027827Z",
     "start_time": "2021-08-01T00:59:43.016665Z"
    }
   },
   "outputs": [],
   "source": [
    "# Demonstration of lematization\n",
    "\n",
    "lematize(tp1(single_row['Title']))\n",
    "#lematize(single_row['Title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equipped-retrieval",
   "metadata": {},
   "source": [
    "#### Unprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-snapshot",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T07:25:01.875323Z",
     "start_time": "2021-08-01T07:25:01.858252Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_db['Title'].iloc[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "available-height",
   "metadata": {},
   "source": [
    "#### Processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-burton",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T07:25:27.562359Z",
     "start_time": "2021-08-01T07:25:27.557862Z"
    }
   },
   "outputs": [],
   "source": [
    "scraped_db['Title'].iloc[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biological-level",
   "metadata": {},
   "source": [
    "### 2.1.1 Preprocess entire dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-alexander",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T00:59:43.834681Z",
     "start_time": "2021-08-01T00:59:43.030064Z"
    }
   },
   "outputs": [],
   "source": [
    "processed_db = scraped_db.copy()\n",
    "\n",
    "def preprocess_df(df):\n",
    "    df.Title = df.Title.apply(tp1)\n",
    "    df.Author = df.Author.str.lower()\n",
    "    df = df.drop(columns=['Author','Published'], axis=1)\n",
    "    return df\n",
    "    \n",
    "preprocess_df(processed_db)\n",
    "processed_db.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offshore-driver",
   "metadata": {},
   "source": [
    "## 2.2 Index Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-water",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T00:59:43.845672Z",
     "start_time": "2021-08-01T00:59:43.837012Z"
    }
   },
   "outputs": [],
   "source": [
    "single = processed_db.loc[0,:].copy()\n",
    "print(single)\n",
    "indexing_trial = {}\n",
    "\n",
    "words = single.Title.split()\n",
    "SN = single.SN\n",
    "word = words[0]\n",
    "example = {word: [SN]}\n",
    "\n",
    "print('=====================================================================')\n",
    "print('Sample index')\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upper-flour",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T00:59:43.854491Z",
     "start_time": "2021-08-01T00:59:43.848459Z"
    }
   },
   "outputs": [],
   "source": [
    "## Indexer Function\n",
    "def apply_index(inputs, index):\n",
    "    words = inputs.Title.split()\n",
    "    SN = int(inputs.SN)\n",
    "    for word in words:\n",
    "        if word in index.keys():\n",
    "            if SN not in index[word]:\n",
    "                index[word].append(SN)\n",
    "        else:\n",
    "            index[word] = [SN]\n",
    "    return index\n",
    "\n",
    "indx = apply_index(inputs=single, index= {})\n",
    "#print(indx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selective-senior",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T02:46:26.572666Z",
     "start_time": "2021-07-31T02:46:26.567533Z"
    }
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-amsterdam",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T00:59:44.790404Z",
     "start_time": "2021-08-01T00:59:43.857267Z"
    }
   },
   "outputs": [],
   "source": [
    "def full_index(df, index):\n",
    "    for x in range(len(df)):\n",
    "        inpt = df.loc[x,:]\n",
    "        ind = apply_index(inputs=inpt, index=index)\n",
    "    return ind\n",
    "\n",
    "def construct_index(df, index):\n",
    "    queue = preprocess_df(df)\n",
    "    ind = full_index(df=queue, index=index)\n",
    "    return ind\n",
    "\n",
    "indexed = full_index(processed_db, \n",
    "                     index = {})\n",
    "\n",
    "\n",
    "indexes = construct_index(df=scraped_db, \n",
    "                          index = {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-piano",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T00:59:44.827243Z",
     "start_time": "2021-08-01T00:59:44.796816Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('indexes.json', 'w') as new_f:\n",
    "    json.dump(indexes, new_f, sort_keys=True, indent=4)\n",
    "    \n",
    "with open('indexes.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "def index_2(df, x_path):\n",
    "    if len(df) > 0:\n",
    "        with open(x_path, 'r') as file:\n",
    "            prior_index = json.load(file)\n",
    "        new_index = construct_index(df = df, index = prior_index)\n",
    "        with open(x_path, 'w') as new_f:\n",
    "            json.dump(new_index, new_f, sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-jesus",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T10:41:54.049783Z",
     "start_time": "2021-08-01T10:41:53.953783Z"
    }
   },
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressing-editing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T23:13:44.430869Z",
     "start_time": "2021-08-01T23:13:44.285366Z"
    }
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-paintball",
   "metadata": {},
   "source": [
    "## 3.  Query Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-football",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T11:02:51.119226Z",
     "start_time": "2021-08-01T11:02:51.112657Z"
    }
   },
   "outputs": [],
   "source": [
    "def demonstrate_query_processing():\n",
    "    sample = input('Enter Search Terms: ')\n",
    "    processed_query = tp1(sample)\n",
    "    #print(f'User Search Query: {sample}')\n",
    "    print(f'Processed Search Query: {processed_query}')\n",
    "    return processed_query\n",
    "    \n",
    "#demonstrate_query_processing()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italian-turkish",
   "metadata": {},
   "source": [
    "### 3.1.  Split Query into individual terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handed-client",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T11:03:01.618023Z",
     "start_time": "2021-08-01T11:02:59.088852Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_query(terms):\n",
    "    each = tp1(terms)\n",
    "    return each.split()\n",
    "\n",
    "dqp = demonstrate_query_processing()\n",
    "dqp\n",
    "print(f'Split Query: {split_query(dqp)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-postage",
   "metadata": {},
   "source": [
    "### 3.2.  Boolean Functionalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-denial",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T01:00:26.010007Z",
     "start_time": "2021-08-01T01:00:26.004950Z"
    }
   },
   "outputs": [],
   "source": [
    "def union(lists):\n",
    "    union = list(set.union(*map(set, lists)))\n",
    "    union.sort()\n",
    "    return union\n",
    "\n",
    "def intersection(lists):\n",
    "    intersect = list(set.intersection(*map(set, lists)))\n",
    "    intersect.sort()\n",
    "    return intersect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circular-distinction",
   "metadata": {},
   "source": [
    "### 3.3. Search Engine Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-pottery",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T01:00:26.020938Z",
     "start_time": "2021-08-01T01:00:26.012920Z"
    }
   },
   "outputs": [],
   "source": [
    "def vertical_search_engine(df, query, index=indexes):\n",
    "    query_split = split_query(query)\n",
    "    retrieved = []\n",
    "    for word in query_split:\n",
    "        if word in index.keys():\n",
    "            retrieved.append(index[word])\n",
    "            \n",
    "            \n",
    "    # Ranked Retrieval\n",
    "    if len(retrieved)>0:\n",
    "        high_rank_result = intersection(retrieved)\n",
    "        low_rank_result = union(retrieved) \n",
    "        c = [x for x in low_rank_result if x not in high_rank_result]      \n",
    "        high_rank_result.extend(c)\n",
    "        result = high_rank_result\n",
    "        \n",
    "        final_output = df[df.SN.isin(result)].reset_index(drop=True)\n",
    "    \n",
    "        # Return result in order of Intersection ----> Union\n",
    "        dummy = pd.Series(result, name = 'SN').to_frame()\n",
    "        result = pd.merge(dummy, final_output, on='SN', how = 'left')\n",
    "        \n",
    "    else:\n",
    "        result = 'No result found'\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-killer",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T01:00:37.508501Z",
     "start_time": "2021-08-01T01:00:26.023723Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_search_engine():\n",
    "    xtest = scraped_db.copy()\n",
    "    query = input(\"Enter your search query: \")\n",
    "    return vertical_search_engine(xtest, query, indexed)\n",
    "    \n",
    "test_search_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-crazy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T11:43:05.137930Z",
     "start_time": "2021-08-01T11:43:05.131660Z"
    }
   },
   "outputs": [],
   "source": [
    "def final_engine(results):\n",
    "    if type(results) != 'list':\n",
    "        return results\n",
    "        #print(results)\n",
    "    else:\n",
    "        for i in range(len(results)):\n",
    "            printout = results.loc[i, :]\n",
    "            #print(printout['Title'])\n",
    "            #print(printout['Author'])\n",
    "            #print(printout['Published'])\n",
    "            #print(printout['Link'])\n",
    "            #print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-astrology",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T11:46:39.943876Z",
     "start_time": "2021-08-01T11:46:39.927460Z"
    }
   },
   "outputs": [],
   "source": [
    "scraped_db['Author'].iloc[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-savings",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T11:44:03.697525Z",
     "start_time": "2021-08-01T11:43:54.760859Z"
    }
   },
   "outputs": [],
   "source": [
    "final_engine(test_search_engine())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "first-toilet",
   "metadata": {},
   "source": [
    "## 4. Schedule Crawler for every week\n",
    "\n",
    "To demonstrate a weekly scheduled crawling, the following parameters are defined:\n",
    "\n",
    "* `interval` : Represents number of days in reality. In this code, it represents only seconds for demonstration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-prayer",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T01:05:57.578325Z",
     "start_time": "2021-08-01T01:00:37.523485Z"
    }
   },
   "outputs": [],
   "source": [
    "days = 0\n",
    "interval = 7\n",
    "while days <= 1:\n",
    "    scrape(mx)\n",
    "    print(f\"Crawled at {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f'Next crawl scheduled after {interval} days')\n",
    "    time.sleep(interval)\n",
    "    days = days + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-biotechnology",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "processed-movement",
   "metadata": {},
   "source": [
    "# 5. GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "patient-victim",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T01:15:13.914499Z",
     "start_time": "2021-08-01T01:15:13.885800Z"
    }
   },
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from tkinter import messagebox\n",
    "from PIL import Image, ImageTk \n",
    "from tkinter import scrolledtext\n",
    "from pandastable import Table, TableModel\n",
    "from contextlib import suppress\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "image1 = Image.open('coventry-university-logo.png')\n",
    "resized_image1 = image1.resize((500,300), Image.ANTIALIAS)\n",
    "\n",
    "def new_gui(image1):\n",
    "    window = Tk()\n",
    "    window.configure(bg='#0F1E9D')\n",
    "    window.title(\"Coventry University Search Engine\")\n",
    "    window.geometry('1100x600')\n",
    "    \n",
    "    lbl = Label(window, text=\"Search Engine\",bg=\"#0F1E9D\", font=(\"Arial Bold\", 30), padx=5, pady=5)\n",
    "    lbl.grid(column=1, row=0)\n",
    "    \n",
    "    lbl2 = Label(window, text=\"Enter your search query here ===>\", bg=\"#0F1E9D\",font=(\"Arial\", 15), padx=5, pady=5)\n",
    "    lbl2.grid(column=0, row=1)\n",
    "    \n",
    "    \n",
    "    img = ImageTk.PhotoImage(image1)\n",
    "    \n",
    "    lbl3 = Label(image=img)\n",
    "    lbl3.image = img\n",
    "    lbl3.grid(column=1, row=3, padx=5, pady=5)\n",
    "    \n",
    "    \n",
    "    \n",
    "    query = Entry(window,width=40)\n",
    "    query.grid(column=1, row=1,  padx=5, pady=5)\n",
    "    \n",
    "    results = Canvas(window, height=30, width=250)\n",
    "    results.grid(column=1, row=2, padx=5, pady=5)\n",
    "    \n",
    "    # Entry\n",
    "    def getInputBoxValue():\n",
    "        userInput = query.get()\n",
    "        return userInput\n",
    "\n",
    "    \n",
    "    # Button\n",
    "    def clicked():\n",
    "        search()\n",
    "        #pass\n",
    "        \n",
    "    def no_result():\n",
    "        messagebox.showwarning(\"Warning\", \"No results found. Please try different search terms\")\n",
    "        \n",
    "    \n",
    "    def search():\n",
    "        xtest = scraped_db.copy()\n",
    "        q = query.get()\n",
    "        f = Frame(window)\n",
    "        df = vertical_search_engine(xtest, q, indexed)\n",
    "        if type(df) == str:\n",
    "            no_result()\n",
    "        else:\n",
    "            pt = Table(results)\n",
    "            try:\n",
    "                table = pt = Table(results, dataframe=df)\n",
    "                pt.show()\n",
    "            except AttributeError:\n",
    "                pass\n",
    "            \n",
    "    def close_window():\n",
    "        if messagebox.askokcancel(\"Quit\", \"Quit Programme?\"):\n",
    "            window.destroy()\n",
    "        \n",
    "    \n",
    "    btn = Button(window, text=\"Search\",bg=\"#0F1E9D\", command=clicked)\n",
    "    btn.grid(column=2, row=1)\n",
    "    \n",
    "    \n",
    "\n",
    "    window.protocol(\"WM_DELETE_WINDOW\", close_window)       \n",
    "    window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-spray",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-01T23:14:02.698938Z",
     "start_time": "2021-08-01T23:14:02.696390Z"
    }
   },
   "outputs": [],
   "source": [
    "new_gui(resized_image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-butterfly",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
